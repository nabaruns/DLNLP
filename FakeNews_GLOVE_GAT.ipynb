{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/4tb/nabarun/nlp/Fake-News-Detection/codebase\n"
     ]
    }
   ],
   "source": [
    "%cd /4tb/nabarun/nlp/Fake-News-Detection/codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\t       execute_bf_pf.py        new_adj_mat_separately.py\r\n",
      "__init__.py\t       execute_cora_sparse.py  pre_trained\r\n",
      "__pycache__\t       feature_matrix.py       requirements.txt\r\n",
      "data\t\t       gat_adj_features.py     utils\r\n",
      "data_preprocessing.py  models\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow==1.0.1\n",
      "  Downloading bert_tensorflow-1.0.1-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 1.9 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six in /home/nabarun/.local/lib/python3.6/site-packages (from bert-tensorflow==1.0.1) (1.12.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "  Attempting uninstall: bert-tensorflow\n",
      "    Found existing installation: bert-tensorflow 1.0.4\n",
      "    Uninstalling bert-tensorflow-1.0.4:\n",
      "      Successfully uninstalled bert-tensorflow-1.0.4\n",
      "Successfully installed bert-tensorflow-1.0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user tensorflow==1.15.0\n",
    "!pip3 install --user bert-tensorflow==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en_core_web_md==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz (50.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 50.8 MB 1.5 MB/s eta 0:00:01    |██▉                             | 4.5 MB 387 kB/s eta 0:02:00     |████████████████████████████▌   | 45.1 MB 404 kB/s eta 0:00:14\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/nabarun/.local/lib/python3.6/site-packages (from en_core_web_md==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: setuptools in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (50.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.56.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/nabarun/.local/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/nabarun/.local/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nabarun/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/nabarun/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/nabarun/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/nabarun/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/nabarun/.local/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.4.0)\n",
      "Building wheels for collected packages: en-core-web-md\n",
      "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-md: filename=en_core_web_md-2.3.1-py3-none-any.whl size=50916641 sha256=3f3780592e86475b7b15f02a5d31856e28c3d95882ae8034f0604b23230c9a44\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1x2ealbt/wheels/52/35/5a/21d21ba55fc116713b5b84c0620e3ebdccb752021aefbeb90f\n",
      "Successfully built en-core-web-md\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-2.3.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nabarun/.local/lib/python3.6/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Dataset: BuzzFeed\n",
      "----- Opt. hyperparams -----\n",
      "lr: 0.01\n",
      "l2_coef: 0.0005\n",
      "----- Archi. hyperparams -----\n",
      "nb. layers: 1\n",
      "nb. units per layer: [8]\n",
      "nb. attention heads: [8, 1]\n",
      "residual: False\n",
      "nonlinearity: <function elu at 0x7fd2c21662f0>\n",
      "model: <class 'models.gat.GAT'>\n",
      "BuzzFeed\n",
      "WARNING:tensorflow:From execute_bf_pf.py:85: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/utils/layers.py:9: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/utils/layers.py:11: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /home/nabarun/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/models/base_gattn.py:41: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/models/base_gattn.py:12: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/models/base_gattn.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From execute_bf_pf.py:106: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From execute_bf_pf.py:108: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From execute_bf_pf.py:108: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From execute_bf_pf.py:114: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-01-21 15:48:57.184029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-01-21 15:48:57.193885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:4b:00.0\n",
      "2021-01-21 15:48:57.194357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:4c:00.0\n",
      "2021-01-21 15:48:57.194820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:4d:00.0\n",
      "2021-01-21 15:48:57.195283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:4e:00.0\n",
      "2021-01-21 15:48:57.195379: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:48:57.195446: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:48:57.195525: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:48:57.195591: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:48:57.195651: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:48:57.195731: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:48:57.198521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-01-21 15:48:57.198541: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-01-21 15:48:57.198863: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-01-21 15:48:57.221680: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2999765000 Hz\n",
      "2021-01-21 15:48:57.222296: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb700030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-01-21 15:48:57.222336: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-01-21 15:48:57.767877: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ecae50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-01-21 15:48:57.767942: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-01-21 15:48:57.767969: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-01-21 15:48:57.767998: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-01-21 15:48:57.768019: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-01-21 15:48:57.768567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-01-21 15:48:57.768599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
      "Training: loss = 11.06839, acc = 0.63303 | Val: loss = 4.06865, acc = 0.77778\n",
      "Training: loss = 8.29733, acc = 0.38532 | Val: loss = 4.42475, acc = 0.77778\n",
      "Training: loss = 139.47224, acc = 0.57798 | Val: loss = 4.56849, acc = 0.77778\n",
      "Training: loss = 137.98888, acc = 0.54128 | Val: loss = 4.73351, acc = 0.75000\n",
      "Training: loss = 550.35303, acc = 0.50459 | Val: loss = 4.81530, acc = 0.75000\n",
      "Training: loss = 35.39355, acc = 0.38532 | Val: loss = 5.06700, acc = 0.75000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss = 15.09789, acc = 0.57798 | Val: loss = 5.52764, acc = 0.75000\n",
      "Training: loss = 71.06297, acc = 0.49541 | Val: loss = 6.09818, acc = 0.75000\n",
      "Training: loss = 73.60207, acc = 0.42202 | Val: loss = 6.51667, acc = 0.75000\n",
      "Training: loss = 94.22901, acc = 0.51376 | Val: loss = 6.97730, acc = 0.75000\n",
      "Training: loss = 32.14556, acc = 0.49541 | Val: loss = 7.42957, acc = 0.75000\n",
      "Training: loss = 32.81705, acc = 0.40367 | Val: loss = 8.00271, acc = 0.75000\n",
      "Training: loss = 23.47179, acc = 0.60550 | Val: loss = 8.36538, acc = 0.75000\n",
      "Training: loss = 9.44831, acc = 0.44954 | Val: loss = 8.68811, acc = 0.75000\n",
      "Training: loss = 4.00401, acc = 0.59633 | Val: loss = 9.05686, acc = 0.75000\n",
      "Training: loss = 34.71558, acc = 0.46789 | Val: loss = 9.59252, acc = 0.75000\n",
      "Training: loss = 52.48663, acc = 0.55963 | Val: loss = 10.35316, acc = 0.75000\n",
      "Training: loss = 11.02527, acc = 0.59633 | Val: loss = 10.69845, acc = 0.75000\n",
      "Training: loss = 17.48945, acc = 0.51376 | Val: loss = 11.01338, acc = 0.75000\n",
      "Training: loss = 19.75961, acc = 0.52294 | Val: loss = 11.33480, acc = 0.75000\n",
      "Training: loss = 23.65152, acc = 0.47706 | Val: loss = 11.57282, acc = 0.75000\n",
      "Training: loss = 39.34845, acc = 0.45872 | Val: loss = 11.72214, acc = 0.75000\n",
      "Training: loss = 9.22942, acc = 0.49541 | Val: loss = 11.91677, acc = 0.75000\n",
      "Training: loss = 17.51125, acc = 0.49541 | Val: loss = 12.25291, acc = 0.75000\n",
      "Training: loss = 58.89924, acc = 0.57798 | Val: loss = 12.62635, acc = 0.75000\n",
      "Training: loss = 52.56744, acc = 0.50459 | Val: loss = 12.96762, acc = 0.75000\n",
      "Training: loss = 10.29330, acc = 0.45872 | Val: loss = 13.37022, acc = 0.75000\n",
      "Training: loss = 2.71872, acc = 0.51376 | Val: loss = 13.77241, acc = 0.75000\n",
      "Training: loss = 13.24904, acc = 0.44954 | Val: loss = 14.18014, acc = 0.75000\n",
      "Training: loss = 2.60184, acc = 0.53211 | Val: loss = 14.56071, acc = 0.75000\n",
      "Training: loss = 27.82066, acc = 0.50459 | Val: loss = 14.97515, acc = 0.75000\n",
      "Training: loss = 20.75756, acc = 0.44037 | Val: loss = 15.35233, acc = 0.75000\n",
      "Training: loss = 1.24696, acc = 0.49541 | Val: loss = 15.67338, acc = 0.75000\n",
      "Training: loss = 144.78435, acc = 0.47706 | Val: loss = 16.08877, acc = 0.75000\n",
      "Training: loss = 16.04339, acc = 0.43119 | Val: loss = 16.29506, acc = 0.75000\n",
      "Training: loss = 0.87157, acc = 0.51376 | Val: loss = 16.39566, acc = 0.75000\n",
      "Training: loss = 2.45417, acc = 0.36697 | Val: loss = 16.52895, acc = 0.75000\n",
      "Training: loss = 9.26163, acc = 0.49541 | Val: loss = 16.41624, acc = 0.75000\n",
      "Training: loss = 0.77514, acc = 0.66972 | Val: loss = 16.35742, acc = 0.75000\n",
      "Training: loss = 11.16046, acc = 0.55046 | Val: loss = 16.35584, acc = 0.75000\n",
      "Training: loss = 1.01610, acc = 0.64220 | Val: loss = 16.36795, acc = 0.75000\n",
      "Training: loss = 2.32269, acc = 0.65138 | Val: loss = 16.39166, acc = 0.75000\n",
      "Training: loss = 48.02517, acc = 0.42202 | Val: loss = 16.34673, acc = 0.75000\n",
      "Training: loss = 11.29823, acc = 0.55963 | Val: loss = 16.16484, acc = 0.75000\n",
      "Training: loss = 49.87727, acc = 0.49541 | Val: loss = 16.07935, acc = 0.75000\n",
      "Training: loss = 10.10147, acc = 0.48624 | Val: loss = 15.96346, acc = 0.75000\n",
      "Training: loss = 8.24445, acc = 0.44037 | Val: loss = 15.82705, acc = 0.75000\n",
      "Training: loss = 4.30560, acc = 0.62385 | Val: loss = 15.27986, acc = 0.75000\n",
      "Training: loss = 24.85398, acc = 0.45872 | Val: loss = 14.76770, acc = 0.75000\n",
      "Training: loss = 38.64460, acc = 0.48624 | Val: loss = 14.79630, acc = 0.75000\n",
      "Training: loss = 14.55732, acc = 0.48624 | Val: loss = 14.85163, acc = 0.75000\n",
      "Training: loss = 6.27141, acc = 0.65138 | Val: loss = 14.88534, acc = 0.75000\n",
      "Training: loss = 18.14353, acc = 0.46789 | Val: loss = 13.35450, acc = 0.75000\n",
      "Training: loss = 11.46319, acc = 0.48624 | Val: loss = 13.06359, acc = 0.75000\n",
      "Training: loss = 123.01198, acc = 0.48624 | Val: loss = 13.13726, acc = 0.75000\n",
      "Training: loss = 11.58950, acc = 0.43119 | Val: loss = 13.11127, acc = 0.75000\n",
      "Training: loss = 20.10981, acc = 0.40367 | Val: loss = 13.15228, acc = 0.75000\n",
      "Training: loss = 4.39904, acc = 0.49541 | Val: loss = 13.20554, acc = 0.75000\n",
      "Training: loss = 1.98683, acc = 0.48624 | Val: loss = 13.27795, acc = 0.75000\n",
      "Training: loss = 1.39538, acc = 0.49541 | Val: loss = 13.36857, acc = 0.75000\n",
      "Training: loss = 1.09094, acc = 0.52294 | Val: loss = 13.45634, acc = 0.75000\n",
      "Training: loss = 9.78051, acc = 0.52294 | Val: loss = 13.55084, acc = 0.75000\n",
      "Training: loss = 14.64468, acc = 0.57798 | Val: loss = 13.63603, acc = 0.75000\n",
      "Training: loss = 9.20771, acc = 0.49541 | Val: loss = 13.71977, acc = 0.75000\n",
      "Training: loss = 8.54638, acc = 0.32110 | Val: loss = 13.79463, acc = 0.75000\n",
      "Training: loss = 15.78128, acc = 0.39450 | Val: loss = 13.85942, acc = 0.75000\n",
      "Training: loss = 4.59180, acc = 0.50459 | Val: loss = 13.91754, acc = 0.75000\n",
      "Training: loss = 10.60752, acc = 0.44037 | Val: loss = 13.96692, acc = 0.75000\n",
      "Training: loss = 13.47483, acc = 0.37615 | Val: loss = 13.99224, acc = 0.75000\n",
      "Training: loss = 3.71830, acc = 0.47706 | Val: loss = 14.01918, acc = 0.75000\n",
      "Training: loss = 4.31823, acc = 0.65138 | Val: loss = 14.04538, acc = 0.75000\n",
      "Training: loss = 0.84735, acc = 0.57798 | Val: loss = 14.06742, acc = 0.75000\n",
      "Training: loss = 1.31429, acc = 0.53211 | Val: loss = 14.09842, acc = 0.75000\n",
      "Training: loss = 7.62267, acc = 0.48624 | Val: loss = 14.15875, acc = 0.75000\n",
      "Training: loss = 7.38707, acc = 0.49541 | Val: loss = 14.25749, acc = 0.75000\n",
      "Training: loss = 1.56948, acc = 0.39450 | Val: loss = 14.35865, acc = 0.75000\n",
      "Training: loss = 1.63965, acc = 0.50459 | Val: loss = 14.45721, acc = 0.75000\n",
      "Training: loss = 3.12134, acc = 0.46789 | Val: loss = 14.55996, acc = 0.75000\n",
      "Training: loss = 1.64866, acc = 0.70642 | Val: loss = 14.69431, acc = 0.75000\n",
      "Training: loss = 1.36867, acc = 0.51376 | Val: loss = 14.84558, acc = 0.75000\n",
      "Training: loss = 0.65779, acc = 0.67890 | Val: loss = 14.99981, acc = 0.75000\n",
      "Training: loss = 1.98744, acc = 0.45872 | Val: loss = 15.15498, acc = 0.75000\n",
      "Training: loss = 9.44454, acc = 0.48624 | Val: loss = 15.33246, acc = 0.75000\n",
      "Training: loss = 16.13997, acc = 0.46789 | Val: loss = 15.52587, acc = 0.75000\n",
      "Training: loss = 2.54701, acc = 0.50459 | Val: loss = 15.57026, acc = 0.75000\n",
      "Training: loss = 5.89000, acc = 0.54128 | Val: loss = 15.61045, acc = 0.75000\n",
      "Training: loss = 3.10730, acc = 0.52294 | Val: loss = 15.65037, acc = 0.75000\n",
      "Training: loss = 1.20576, acc = 0.62385 | Val: loss = 15.67736, acc = 0.75000\n",
      "Training: loss = 7.31219, acc = 0.56881 | Val: loss = 15.71181, acc = 0.75000\n",
      "Training: loss = 4.45095, acc = 0.44954 | Val: loss = 15.60670, acc = 0.75000\n",
      "Training: loss = 2.71373, acc = 0.47706 | Val: loss = 15.48375, acc = 0.75000\n",
      "Training: loss = 2.75305, acc = 0.43119 | Val: loss = 15.38396, acc = 0.75000\n",
      "Training: loss = 1.46704, acc = 0.51376 | Val: loss = 15.27838, acc = 0.75000\n",
      "Training: loss = 1.05455, acc = 0.51376 | Val: loss = 15.18350, acc = 0.75000\n",
      "Training: loss = 13.15186, acc = 0.59633 | Val: loss = 15.09799, acc = 0.75000\n",
      "Training: loss = 3.15936, acc = 0.50459 | Val: loss = 15.01823, acc = 0.75000\n",
      "Training: loss = 2.55235, acc = 0.61468 | Val: loss = 14.95076, acc = 0.75000\n",
      "Training: loss = 1.22725, acc = 0.65138 | Val: loss = 14.88911, acc = 0.75000\n",
      "Training: loss = 1.03639, acc = 0.57798 | Val: loss = 14.83201, acc = 0.75000\n",
      "Training: loss = 3.73927, acc = 0.57798 | Val: loss = 14.77782, acc = 0.75000\n",
      "Training: loss = 1.04165, acc = 0.51376 | Val: loss = 14.71714, acc = 0.75000\n",
      "Training: loss = 3.88346, acc = 0.56881 | Val: loss = 14.66135, acc = 0.75000\n",
      "Training: loss = 1.05125, acc = 0.61468 | Val: loss = 14.60702, acc = 0.75000\n",
      "Early stop! Min loss:  4.068653583526611 , Max accuracy:  0.7777777314186096\n",
      "Early stop model validation loss:  4.068653583526611 , accuracy:  0.7777777314186096\n",
      "Test loss: 4.150264263153076 ; Test accuracy: 0.7499999403953552\n"
     ]
    }
   ],
   "source": [
    "!python3 execute_bf_pf.py BuzzFeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nabarun/.local/lib/python3.6/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Dataset: PolitiFact\n",
      "----- Opt. hyperparams -----\n",
      "lr: 0.01\n",
      "l2_coef: 0.005\n",
      "----- Archi. hyperparams -----\n",
      "nb. layers: 1\n",
      "nb. units per layer: [8]\n",
      "nb. attention heads: [8, 1]\n",
      "residual: False\n",
      "nonlinearity: <function elu at 0x7fdb4bc992f0>\n",
      "model: <class 'models.gat.GAT'>\n",
      "PolitiFact\n",
      "WARNING:tensorflow:From execute_bf_pf.py:85: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/utils/layers.py:9: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/utils/layers.py:11: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /home/nabarun/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/models/base_gattn.py:41: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/models/base_gattn.py:12: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /4tb/nabarun/nlp/Fake-News-Detection/codebase/models/base_gattn.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From execute_bf_pf.py:106: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From execute_bf_pf.py:108: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From execute_bf_pf.py:108: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From execute_bf_pf.py:114: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-01-21 15:50:27.639456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-01-21 15:50:27.646984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:4b:00.0\n",
      "2021-01-21 15:50:27.647399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:4c:00.0\n",
      "2021-01-21 15:50:27.647805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:4d:00.0\n",
      "2021-01-21 15:50:27.648209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:4e:00.0\n",
      "2021-01-21 15:50:27.648286: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:50:27.648349: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:50:27.648409: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:50:27.648467: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:50:27.648525: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:50:27.648583: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory\n",
      "2021-01-21 15:50:27.651319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-01-21 15:50:27.651340: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-01-21 15:50:27.651646: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-01-21 15:50:27.673652: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2999765000 Hz\n",
      "2021-01-21 15:50:27.674150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8e82790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-01-21 15:50:27.674173: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-01-21 15:50:28.431507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x748d9e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-01-21 15:50:28.431556: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-01-21 15:50:28.431572: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-01-21 15:50:28.431586: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-01-21 15:50:28.431598: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-01-21 15:50:28.432040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-01-21 15:50:28.432066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
      "Training: loss = 32.36296, acc = 0.45139 | Val: loss = 0.33545, acc = 0.33333\n",
      "Training: loss = 44.66405, acc = 0.52083 | Val: loss = 0.32843, acc = 0.39583\n",
      "Training: loss = 28.35822, acc = 0.49306 | Val: loss = 0.32422, acc = 0.64583\n",
      "Training: loss = 64.73610, acc = 0.32639 | Val: loss = 0.36068, acc = 0.66667\n",
      "Training: loss = 9.50340, acc = 0.40972 | Val: loss = 0.41618, acc = 0.72917\n",
      "Training: loss = 19.93621, acc = 0.59028 | Val: loss = 0.45618, acc = 0.72917\n",
      "Training: loss = 24.79816, acc = 0.40278 | Val: loss = 0.51466, acc = 0.70833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: loss = 23.40002, acc = 0.52083 | Val: loss = 0.59865, acc = 0.70833\n",
      "Training: loss = 91.57088, acc = 0.53472 | Val: loss = 0.69314, acc = 0.68750\n",
      "Training: loss = 32.84015, acc = 0.40972 | Val: loss = 0.78390, acc = 0.66667\n",
      "Training: loss = 14.59990, acc = 0.40278 | Val: loss = 0.89482, acc = 0.60417\n",
      "Training: loss = 6.83432, acc = 0.64583 | Val: loss = 1.00610, acc = 0.66667\n",
      "Training: loss = 10.34340, acc = 0.59028 | Val: loss = 1.14162, acc = 0.66667\n",
      "Training: loss = 20.84521, acc = 0.59722 | Val: loss = 1.28258, acc = 0.66667\n",
      "Training: loss = 5.73137, acc = 0.47917 | Val: loss = 1.40709, acc = 0.66667\n",
      "Training: loss = 2.64465, acc = 0.46528 | Val: loss = 1.51164, acc = 0.66667\n",
      "Training: loss = 5.49116, acc = 0.55556 | Val: loss = 1.61919, acc = 0.66667\n",
      "Training: loss = 5.47004, acc = 0.54861 | Val: loss = 1.73710, acc = 0.66667\n",
      "Training: loss = 10.64214, acc = 0.50000 | Val: loss = 1.84705, acc = 0.66667\n",
      "Training: loss = 9.59348, acc = 0.52083 | Val: loss = 1.93782, acc = 0.66667\n",
      "Training: loss = 10.35508, acc = 0.33333 | Val: loss = 2.01520, acc = 0.66667\n",
      "Training: loss = 3.16930, acc = 0.56250 | Val: loss = 2.07891, acc = 0.66667\n",
      "Training: loss = 25.97044, acc = 0.27778 | Val: loss = 2.11154, acc = 0.66667\n",
      "Training: loss = 2.36774, acc = 0.47222 | Val: loss = 2.14028, acc = 0.66667\n",
      "Training: loss = 80.29951, acc = 0.50000 | Val: loss = 2.20489, acc = 0.66667\n",
      "Training: loss = 18.43892, acc = 0.50694 | Val: loss = 2.29202, acc = 0.66667\n",
      "Training: loss = 37.14733, acc = 0.57639 | Val: loss = 2.37740, acc = 0.66667\n",
      "Training: loss = 96.40102, acc = 0.40278 | Val: loss = 2.47288, acc = 0.66667\n",
      "Training: loss = 142.54401, acc = 0.44444 | Val: loss = 2.58496, acc = 0.66667\n",
      "Training: loss = 9.50232, acc = 0.59722 | Val: loss = 2.70235, acc = 0.66667\n",
      "Training: loss = 6.01267, acc = 0.36111 | Val: loss = 2.81019, acc = 0.66667\n",
      "Training: loss = 9.30584, acc = 0.41667 | Val: loss = 2.90267, acc = 0.66667\n",
      "Training: loss = 5.38466, acc = 0.65278 | Val: loss = 2.99106, acc = 0.66667\n",
      "Training: loss = 68.61600, acc = 0.47917 | Val: loss = 3.08881, acc = 0.66667\n",
      "Training: loss = 93.87675, acc = 0.52083 | Val: loss = 3.20814, acc = 0.66667\n",
      "Training: loss = 2.74724, acc = 0.57639 | Val: loss = 3.32021, acc = 0.66667\n",
      "Training: loss = 23.18257, acc = 0.46528 | Val: loss = 3.42447, acc = 0.66667\n",
      "Training: loss = 8.77425, acc = 0.36806 | Val: loss = 3.54569, acc = 0.66667\n",
      "Training: loss = 20.63657, acc = 0.38889 | Val: loss = 3.66008, acc = 0.66667\n",
      "Training: loss = 3.00468, acc = 0.54861 | Val: loss = 3.75093, acc = 0.66667\n",
      "Training: loss = 14.68525, acc = 0.37500 | Val: loss = 3.80754, acc = 0.66667\n",
      "Training: loss = 0.99258, acc = 0.70139 | Val: loss = 3.85498, acc = 0.66667\n",
      "Training: loss = 6.90629, acc = 0.39583 | Val: loss = 3.89808, acc = 0.66667\n",
      "Training: loss = 4.57464, acc = 0.57639 | Val: loss = 3.92973, acc = 0.66667\n",
      "Training: loss = 3.32224, acc = 0.39583 | Val: loss = 3.95716, acc = 0.66667\n",
      "Training: loss = 1.59980, acc = 0.57639 | Val: loss = 3.98026, acc = 0.66667\n",
      "Training: loss = 3.70935, acc = 0.40278 | Val: loss = 3.99027, acc = 0.66667\n",
      "Training: loss = 22.15003, acc = 0.37500 | Val: loss = 3.99362, acc = 0.66667\n",
      "Training: loss = 4.70039, acc = 0.40972 | Val: loss = 4.00156, acc = 0.66667\n",
      "Training: loss = 1.19886, acc = 0.63889 | Val: loss = 4.00541, acc = 0.66667\n",
      "Training: loss = 2.87727, acc = 0.56250 | Val: loss = 4.00482, acc = 0.66667\n",
      "Training: loss = 13.58586, acc = 0.40972 | Val: loss = 4.02522, acc = 0.66667\n",
      "Training: loss = 2.58301, acc = 0.53472 | Val: loss = 4.03457, acc = 0.66667\n",
      "Training: loss = 4.60056, acc = 0.59028 | Val: loss = 4.05521, acc = 0.66667\n",
      "Training: loss = 8.21999, acc = 0.44444 | Val: loss = 4.07691, acc = 0.66667\n",
      "Training: loss = 2.29832, acc = 0.53472 | Val: loss = 4.09608, acc = 0.66667\n",
      "Training: loss = 1.66044, acc = 0.50000 | Val: loss = 4.10822, acc = 0.66667\n",
      "Training: loss = 2.62102, acc = 0.53472 | Val: loss = 4.11511, acc = 0.66667\n",
      "Training: loss = 2.53483, acc = 0.54167 | Val: loss = 4.12175, acc = 0.66667\n",
      "Training: loss = 0.84994, acc = 0.75000 | Val: loss = 4.12350, acc = 0.66667\n",
      "Training: loss = 1.73946, acc = 0.47917 | Val: loss = 4.12172, acc = 0.66667\n",
      "Training: loss = 1.91466, acc = 0.52778 | Val: loss = 4.12104, acc = 0.66667\n",
      "Training: loss = 3.82061, acc = 0.40278 | Val: loss = 4.12415, acc = 0.66667\n",
      "Training: loss = 2.60376, acc = 0.56250 | Val: loss = 4.12310, acc = 0.66667\n",
      "Training: loss = 1.44214, acc = 0.55556 | Val: loss = 4.11505, acc = 0.66667\n",
      "Training: loss = 2.49243, acc = 0.56250 | Val: loss = 4.10005, acc = 0.66667\n",
      "Training: loss = 5.32577, acc = 0.59722 | Val: loss = 4.11096, acc = 0.66667\n",
      "Training: loss = 2.34584, acc = 0.57639 | Val: loss = 4.12703, acc = 0.66667\n",
      "Training: loss = 2.28477, acc = 0.50000 | Val: loss = 4.13984, acc = 0.66667\n",
      "Training: loss = 6.02925, acc = 0.36806 | Val: loss = 4.15944, acc = 0.66667\n",
      "Training: loss = 2.09565, acc = 0.38194 | Val: loss = 4.17100, acc = 0.66667\n",
      "Training: loss = 1.59761, acc = 0.55556 | Val: loss = 4.17817, acc = 0.66667\n",
      "Training: loss = 6.43711, acc = 0.54167 | Val: loss = 4.19521, acc = 0.66667\n",
      "Training: loss = 1.11944, acc = 0.60417 | Val: loss = 4.20905, acc = 0.66667\n",
      "Training: loss = 1.89670, acc = 0.54167 | Val: loss = 4.22130, acc = 0.66667\n",
      "Training: loss = 2.23332, acc = 0.54861 | Val: loss = 4.23522, acc = 0.66667\n",
      "Training: loss = 1.26192, acc = 0.64583 | Val: loss = 4.24281, acc = 0.66667\n",
      "Training: loss = 6.76855, acc = 0.36111 | Val: loss = 4.30105, acc = 0.66667\n",
      "Training: loss = 3.20025, acc = 0.52778 | Val: loss = 4.34021, acc = 0.66667\n",
      "Training: loss = 2.74965, acc = 0.52083 | Val: loss = 4.36680, acc = 0.66667\n",
      "Training: loss = 1.06833, acc = 0.64583 | Val: loss = 4.38650, acc = 0.66667\n",
      "Training: loss = 1.43747, acc = 0.58333 | Val: loss = 4.39831, acc = 0.66667\n",
      "Training: loss = 1.56940, acc = 0.52083 | Val: loss = 4.40759, acc = 0.66667\n",
      "Training: loss = 1.51584, acc = 0.47222 | Val: loss = 4.41931, acc = 0.66667\n",
      "Training: loss = 1.34661, acc = 0.40972 | Val: loss = 4.42908, acc = 0.66667\n",
      "Training: loss = 1.58347, acc = 0.52778 | Val: loss = 4.43674, acc = 0.66667\n",
      "Training: loss = 1.28725, acc = 0.61806 | Val: loss = 4.43849, acc = 0.66667\n",
      "Training: loss = 1.71999, acc = 0.56250 | Val: loss = 4.43466, acc = 0.66667\n",
      "Training: loss = 1.27737, acc = 0.54861 | Val: loss = 4.42725, acc = 0.66667\n",
      "Training: loss = 1.29196, acc = 0.55556 | Val: loss = 4.41987, acc = 0.66667\n",
      "Training: loss = 2.22762, acc = 0.48611 | Val: loss = 4.40758, acc = 0.66667\n",
      "Training: loss = 16.15197, acc = 0.31250 | Val: loss = 4.38662, acc = 0.66667\n",
      "Training: loss = 1.72469, acc = 0.54861 | Val: loss = 4.36319, acc = 0.66667\n",
      "Training: loss = 1.95539, acc = 0.50694 | Val: loss = 4.34465, acc = 0.66667\n",
      "Training: loss = 1.53285, acc = 0.56944 | Val: loss = 4.32115, acc = 0.66667\n",
      "Training: loss = 1.50703, acc = 0.65972 | Val: loss = 4.29568, acc = 0.66667\n",
      "Training: loss = 1.75049, acc = 0.52083 | Val: loss = 4.26585, acc = 0.66667\n",
      "Training: loss = 1.31347, acc = 0.57639 | Val: loss = 4.23754, acc = 0.66667\n",
      "Training: loss = 1.64338, acc = 0.51389 | Val: loss = 4.20920, acc = 0.66667\n",
      "Training: loss = 0.94154, acc = 0.55556 | Val: loss = 4.17891, acc = 0.66667\n",
      "Training: loss = 1.85968, acc = 0.50000 | Val: loss = 4.15208, acc = 0.66667\n",
      "Training: loss = 1.70751, acc = 0.56944 | Val: loss = 4.12646, acc = 0.66667\n",
      "Training: loss = 1.63878, acc = 0.46528 | Val: loss = 4.10020, acc = 0.66667\n",
      "Training: loss = 1.60225, acc = 0.49306 | Val: loss = 4.06789, acc = 0.66667\n",
      "Training: loss = 1.73993, acc = 0.53472 | Val: loss = 4.03057, acc = 0.66667\n",
      "Training: loss = 1.77324, acc = 0.49306 | Val: loss = 3.99110, acc = 0.66667\n",
      "Early stop! Min loss:  0.3242245018482208 , Max accuracy:  0.7291666865348816\n",
      "Early stop model validation loss:  0.3242245018482208 , accuracy:  0.6458333134651184\n",
      "Test loss: 0.27952462434768677 ; Test accuracy: 0.6458333134651184\n"
     ]
    }
   ],
   "source": [
    "!python3 execute_bf_pf.py PolitiFact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
