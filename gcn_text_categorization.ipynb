{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/4tb/nabarun/nlp/gcn_text_categorization\n"
     ]
    }
   ],
   "source": [
    "%cd /4tb/nabarun/nlp/gcn_text_categorization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.cleaned/' already exists, not overwritten.\n",
      "[nltk_data] Downloading package stopwords to venv/nltk_data/...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[INFO] Cleaned-Corpus Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.cleaned/'\n",
      "[INFO] Rare-Count=<5>\n",
      "[INFO] ========= CLEANED DATA: Removed rare & stop-words. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/meta/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/split_index/' already exists, not overwritten.\n",
      "[INFO] Shuffled-Corpus Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/'\n",
      "[INFO] ========= SHUFFLED DATA: Corpus documents shuffled. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/vocabulary/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/word_vectors/' already exists, not overwritten.\n",
      "[nltk_data] Downloading package wordnet to venv/nltk_data/...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[INFO] Vocabulary Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/vocabulary/'\n",
      "[INFO] Word-Vector Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/word_vectors/'\n",
      "[INFO] ========= PREPARED WORDS: Vocabulary & word-vectors extracted. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/node_features//pubmed' already exists, not overwritten.\n",
      "[INFO] x.shape=   (12422, 300),\t y.shape=   (12422, 3)\n",
      "[INFO] tx.shape=  (5915, 300),\t ty.shape=  (5915, 3)\n",
      "[INFO] allx.shape=(14254, 300),\t ally.shape=(14254, 3)\n",
      "[INFO] ========= EXTRACTED NODE FEATURES: x, y, tx, ty, allx, ally. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/adjacency/' already exists, not overwritten.\n",
      "[INFO] Adjacency Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/adjacency/'\n",
      "[INFO] ========= EXTRACTED ADJACENCY MATRIX: Heterogenous doc-word adjacency matrix. =========\n"
     ]
    }
   ],
   "source": [
    "!venv/bin/python3 preprocess.py pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.cleaned/' already exists, not overwritten.\n",
      "[nltk_data] Downloading package stopwords to venv/nltk_data/...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[INFO] Cleaned-Corpus Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.cleaned/'\n",
      "[INFO] Rare-Count=<5>\n",
      "[INFO] ========= CLEANED DATA: Removed rare & stop-words. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/meta/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/split_index/' already exists, not overwritten.\n",
      "[INFO] Shuffled-Corpus Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/'\n",
      "[INFO] ========= SHUFFLED DATA: Corpus documents shuffled. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/vocabulary/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/word_vectors/' already exists, not overwritten.\n",
      "[nltk_data] Downloading package wordnet to venv/nltk_data/...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[INFO] Vocabulary Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/vocabulary/'\n",
      "[INFO] Word-Vector Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/word_vectors/'\n",
      "[INFO] ========= PREPARED WORDS: Vocabulary & word-vectors extracted. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/node_features//cora' already exists, not overwritten.\n",
      "[INFO] x.shape=   (1707, 300),\t y.shape=   (1707, 7)\n",
      "[INFO] tx.shape=  (812, 300),\t ty.shape=  (812, 7)\n",
      "[INFO] allx.shape=(3239, 300),\t ally.shape=(3239, 7)\n",
      "[INFO] ========= EXTRACTED NODE FEATURES: x, y, tx, ty, allx, ally. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/adjacency/' already exists, not overwritten.\n",
      "[INFO] Adjacency Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/adjacency/'\n",
      "[INFO] ========= EXTRACTED ADJACENCY MATRIX: Heterogenous doc-word adjacency matrix. =========\n"
     ]
    }
   ],
   "source": [
    "!venv/bin/python3 preprocess.py cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.cleaned/' already exists, not overwritten.\n",
      "[nltk_data] Downloading package stopwords to venv/nltk_data/...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[INFO] Cleaned-Corpus Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.cleaned/'\n",
      "[INFO] Rare-Count=<5>\n",
      "[INFO] ========= CLEANED DATA: Removed rare & stop-words. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/meta/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/split_index/' already exists, not overwritten.\n",
      "[INFO] Shuffled-Corpus Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/'\n",
      "[INFO] ========= SHUFFLED DATA: Corpus documents shuffled. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/vocabulary/' already exists, not overwritten.\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/word_vectors/' already exists, not overwritten.\n",
      "[nltk_data] Downloading package wordnet to venv/nltk_data/...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[INFO] Vocabulary Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/vocabulary/'\n",
      "[INFO] Word-Vector Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/word_vectors/'\n",
      "[INFO] ========= PREPARED WORDS: Vocabulary & word-vectors extracted. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/node_features//citeseer' already exists, not overwritten.\n",
      "[INFO] x.shape=   (2088, 300),\t y.shape=   (2088, 6)\n",
      "[INFO] tx.shape=  (993, 300),\t ty.shape=  (993, 6)\n",
      "[INFO] allx.shape=(5834, 300),\t ally.shape=(5834, 6)\n",
      "[INFO] ========= EXTRACTED NODE FEATURES: x, y, tx, ty, allx, ally. =========\n",
      "[WARN] directory:'/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/adjacency/' already exists, not overwritten.\n",
      "[INFO] Adjacency Dir='/4tb/nabarun/nlp/gcn_text_categorization/data/corpus.shuffled/adjacency/'\n",
      "[INFO] ========= EXTRACTED ADJACENCY MATRIX: Heterogenous doc-word adjacency matrix. =========\n"
     ]
    }
   ],
   "source": [
    "!venv/bin/python3 preprocess.py citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/1/17 20:40:03] Epoch:1, train_loss=1.13128, train_acc=0.21349, val_loss=1.09576, val_acc=0.44565, time=3.51083\n",
      "[2021/1/17 20:40:06] Epoch:2, train_loss=1.07708, train_acc=0.42964, val_loss=1.09327, val_acc=0.50435, time=3.01025\n",
      "[2021/1/17 20:40:09] Epoch:3, train_loss=1.05281, train_acc=0.50370, val_loss=1.08799, val_acc=0.54420, time=3.31329\n",
      "[2021/1/17 20:40:12] Epoch:4, train_loss=1.00376, train_acc=0.54637, val_loss=1.08314, val_acc=0.58261, time=3.20063\n",
      "[2021/1/17 20:40:15] Epoch:5, train_loss=0.95880, train_acc=0.57543, val_loss=1.08007, val_acc=0.62826, time=3.24777\n",
      "[2021/1/17 20:40:19] Epoch:6, train_loss=0.92988, train_acc=0.63500, val_loss=1.07784, val_acc=0.70362, time=3.21606\n",
      "[2021/1/17 20:40:22] Epoch:7, train_loss=0.90873, train_acc=0.71977, val_loss=1.07577, val_acc=0.73261, time=3.16409\n",
      "[2021/1/17 20:40:25] Epoch:8, train_loss=0.88916, train_acc=0.73684, val_loss=1.07362, val_acc=0.73551, time=3.05665\n",
      "[2021/1/17 20:40:28] Epoch:9, train_loss=0.86904, train_acc=0.73660, val_loss=1.07126, val_acc=0.74130, time=2.98209\n",
      "[2021/1/17 20:40:31] Epoch:10, train_loss=0.84688, train_acc=0.74014, val_loss=1.06876, val_acc=0.75072, time=3.42620\n",
      "[2021/1/17 20:40:34] Epoch:11, train_loss=0.82302, train_acc=0.75004, val_loss=1.06652, val_acc=0.76087, time=3.07736\n",
      "[2021/1/17 20:40:37] Epoch:12, train_loss=0.80110, train_acc=0.75970, val_loss=1.06476, val_acc=0.76812, time=2.86938\n",
      "[2021/1/17 20:40:40] Epoch:13, train_loss=0.78338, train_acc=0.76767, val_loss=1.06333, val_acc=0.77101, time=3.11623\n",
      "[2021/1/17 20:40:43] Epoch:14, train_loss=0.76926, train_acc=0.77516, val_loss=1.06203, val_acc=0.77536, time=3.13912\n",
      "[2021/1/17 20:40:47] Epoch:15, train_loss=0.75706, train_acc=0.78248, val_loss=1.06067, val_acc=0.78696, time=3.07263\n",
      "[2021/1/17 20:40:50] Epoch:16, train_loss=0.74522, train_acc=0.79222, val_loss=1.05937, val_acc=0.79928, time=3.18729\n",
      "[2021/1/17 20:40:53] Epoch:17, train_loss=0.73482, train_acc=0.80116, val_loss=1.05834, val_acc=0.80797, time=2.98523\n",
      "[2021/1/17 20:40:56] Epoch:18, train_loss=0.72765, train_acc=0.80365, val_loss=1.05760, val_acc=0.81739, time=3.44012\n",
      "[2021/1/17 20:40:59] Epoch:19, train_loss=0.72311, train_acc=0.80486, val_loss=1.05707, val_acc=0.81667, time=2.97464\n",
      "[2021/1/17 20:41:02] Epoch:20, train_loss=0.71930, train_acc=0.80382, val_loss=1.05667, val_acc=0.82174, time=3.06064\n",
      "[2021/1/17 20:41:05] Epoch:21, train_loss=0.71490, train_acc=0.80647, val_loss=1.05649, val_acc=0.81377, time=3.11471\n",
      "[2021/1/17 20:41:08] Epoch:22, train_loss=0.71135, train_acc=0.80808, val_loss=1.05644, val_acc=0.81014, time=2.95826\n",
      "[2021/1/17 20:41:11] Epoch:23, train_loss=0.70901, train_acc=0.80897, val_loss=1.05633, val_acc=0.81159, time=3.24879\n",
      "[2021/1/17 20:41:15] Epoch:24, train_loss=0.70670, train_acc=0.81098, val_loss=1.05599, val_acc=0.81304, time=3.25048\n",
      "[2021/1/17 20:41:18] Epoch:25, train_loss=0.70319, train_acc=0.81291, val_loss=1.05552, val_acc=0.81667, time=3.17087\n",
      "[2021/1/17 20:41:21] Epoch:26, train_loss=0.69928, train_acc=0.81460, val_loss=1.05510, val_acc=0.82029, time=3.16174\n",
      "[2021/1/17 20:41:24] Epoch:27, train_loss=0.69598, train_acc=0.81726, val_loss=1.05481, val_acc=0.82391, time=3.31527\n",
      "[2021/1/17 20:41:28] Epoch:28, train_loss=0.69325, train_acc=0.81927, val_loss=1.05460, val_acc=0.82391, time=3.48192\n",
      "[2021/1/17 20:41:31] Epoch:29, train_loss=0.69015, train_acc=0.82169, val_loss=1.05446, val_acc=0.82754, time=2.89901\n",
      "[2021/1/17 20:41:34] Epoch:30, train_loss=0.68690, train_acc=0.82652, val_loss=1.05440, val_acc=0.82971, time=2.88846\n",
      "[2021/1/17 20:41:37] Epoch:31, train_loss=0.68417, train_acc=0.82982, val_loss=1.05435, val_acc=0.83116, time=3.13528\n",
      "[2021/1/17 20:41:40] Epoch:32, train_loss=0.68207, train_acc=0.83135, val_loss=1.05418, val_acc=0.82754, time=3.07948\n",
      "[2021/1/17 20:41:43] Epoch:33, train_loss=0.67983, train_acc=0.83256, val_loss=1.05387, val_acc=0.82826, time=3.05233\n",
      "[2021/1/17 20:41:46] Epoch:34, train_loss=0.67735, train_acc=0.83425, val_loss=1.05353, val_acc=0.83116, time=3.02135\n",
      "[2021/1/17 20:41:49] Epoch:35, train_loss=0.67495, train_acc=0.83473, val_loss=1.05323, val_acc=0.83478, time=3.27273\n",
      "[2021/1/17 20:41:52] Epoch:36, train_loss=0.67291, train_acc=0.83658, val_loss=1.05298, val_acc=0.83261, time=3.11704\n",
      "[2021/1/17 20:41:55] Epoch:37, train_loss=0.67083, train_acc=0.83875, val_loss=1.05277, val_acc=0.83043, time=3.07541\n",
      "[2021/1/17 20:41:59] Epoch:38, train_loss=0.66855, train_acc=0.84044, val_loss=1.05262, val_acc=0.83116, time=3.13340\n",
      "[2021/1/17 20:42:01] Epoch:39, train_loss=0.66636, train_acc=0.84262, val_loss=1.05250, val_acc=0.83116, time=2.85684\n",
      "[2021/1/17 20:42:04] Epoch:40, train_loss=0.66452, train_acc=0.84318, val_loss=1.05237, val_acc=0.83261, time=3.08317\n",
      "[2021/1/17 20:42:08] Epoch:41, train_loss=0.66284, train_acc=0.84374, val_loss=1.05219, val_acc=0.83551, time=3.05556\n",
      "[2021/1/17 20:42:11] Epoch:42, train_loss=0.66111, train_acc=0.84439, val_loss=1.05199, val_acc=0.83913, time=3.16869\n",
      "[2021/1/17 20:42:14] Epoch:43, train_loss=0.65951, train_acc=0.84536, val_loss=1.05182, val_acc=0.84203, time=3.19642\n",
      "[2021/1/17 20:42:17] Epoch:44, train_loss=0.65813, train_acc=0.84600, val_loss=1.05171, val_acc=0.84420, time=3.00149\n",
      "[2021/1/17 20:42:20] Epoch:45, train_loss=0.65685, train_acc=0.84680, val_loss=1.05163, val_acc=0.84348, time=3.30720\n",
      "[2021/1/17 20:42:23] Epoch:46, train_loss=0.65549, train_acc=0.84793, val_loss=1.05158, val_acc=0.84493, time=3.25393\n",
      "[2021/1/17 20:42:27] Epoch:47, train_loss=0.65415, train_acc=0.84970, val_loss=1.05155, val_acc=0.84275, time=3.17484\n",
      "[2021/1/17 20:42:29] Epoch:48, train_loss=0.65295, train_acc=0.85091, val_loss=1.05149, val_acc=0.83841, time=2.82654\n",
      "[2021/1/17 20:42:32] Epoch:49, train_loss=0.65181, train_acc=0.85155, val_loss=1.05140, val_acc=0.84058, time=2.99982\n",
      "[2021/1/17 20:42:36] Epoch:50, train_loss=0.65065, train_acc=0.85292, val_loss=1.05128, val_acc=0.84420, time=3.25412\n",
      "[2021/1/17 20:42:39] Epoch:51, train_loss=0.64955, train_acc=0.85421, val_loss=1.05118, val_acc=0.84420, time=3.13324\n",
      "[2021/1/17 20:42:42] Epoch:52, train_loss=0.64859, train_acc=0.85518, val_loss=1.05111, val_acc=0.84420, time=3.02480\n",
      "[2021/1/17 20:42:45] Epoch:53, train_loss=0.64769, train_acc=0.85590, val_loss=1.05106, val_acc=0.84420, time=2.94832\n",
      "[2021/1/17 20:42:48] Epoch:54, train_loss=0.64677, train_acc=0.85695, val_loss=1.05104, val_acc=0.84565, time=3.45690\n",
      "[2021/1/17 20:42:51] Epoch:55, train_loss=0.64588, train_acc=0.85759, val_loss=1.05102, val_acc=0.84493, time=3.07032\n",
      "[2021/1/17 20:42:55] Epoch:56, train_loss=0.64505, train_acc=0.85775, val_loss=1.05097, val_acc=0.84493, time=3.22800\n",
      "[2021/1/17 20:42:58] Epoch:57, train_loss=0.64421, train_acc=0.85920, val_loss=1.05090, val_acc=0.84565, time=3.29000\n",
      "[2021/1/17 20:43:01] Epoch:58, train_loss=0.64333, train_acc=0.85976, val_loss=1.05083, val_acc=0.84493, time=3.00331\n",
      "[2021/1/17 20:43:04] Epoch:59, train_loss=0.64249, train_acc=0.86073, val_loss=1.05078, val_acc=0.84493, time=3.20166\n",
      "[2021/1/17 20:43:07] Epoch:60, train_loss=0.64170, train_acc=0.86194, val_loss=1.05075, val_acc=0.84565, time=3.19208\n",
      "[2021/1/17 20:43:11] Epoch:61, train_loss=0.64093, train_acc=0.86266, val_loss=1.05074, val_acc=0.84565, time=3.25334\n",
      "[2021/1/17 20:43:14] Epoch:62, train_loss=0.64016, train_acc=0.86274, val_loss=1.05073, val_acc=0.84855, time=3.14613\n",
      "[2021/1/17 20:43:17] Epoch:63, train_loss=0.63945, train_acc=0.86323, val_loss=1.05071, val_acc=0.84855, time=3.19295\n",
      "[2021/1/17 20:43:20] Epoch:64, train_loss=0.63874, train_acc=0.86379, val_loss=1.05066, val_acc=0.84928, time=3.19567\n",
      "[2021/1/17 20:43:23] Epoch:65, train_loss=0.63802, train_acc=0.86371, val_loss=1.05062, val_acc=0.84855, time=2.84661\n",
      "[2021/1/17 20:43:26] Epoch:66, train_loss=0.63732, train_acc=0.86403, val_loss=1.05057, val_acc=0.84855, time=3.04471\n",
      "[2021/1/17 20:43:29] Epoch:67, train_loss=0.63665, train_acc=0.86435, val_loss=1.05055, val_acc=0.84855, time=3.24906\n",
      "[2021/1/17 20:43:32] Epoch:68, train_loss=0.63598, train_acc=0.86403, val_loss=1.05053, val_acc=0.84928, time=3.11940\n",
      "[2021/1/17 20:43:36] Epoch:69, train_loss=0.63533, train_acc=0.86508, val_loss=1.05053, val_acc=0.85072, time=3.24849\n",
      "[2021/1/17 20:43:39] Epoch:70, train_loss=0.63472, train_acc=0.86572, val_loss=1.05051, val_acc=0.85072, time=2.99416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/1/17 20:43:42] Epoch:71, train_loss=0.63411, train_acc=0.86621, val_loss=1.05048, val_acc=0.85072, time=2.97431\n",
      "[2021/1/17 20:43:45] Epoch:72, train_loss=0.63351, train_acc=0.86588, val_loss=1.05044, val_acc=0.85000, time=3.52170\n",
      "[2021/1/17 20:43:48] Epoch:73, train_loss=0.63292, train_acc=0.86637, val_loss=1.05042, val_acc=0.85000, time=3.31258\n",
      "[2021/1/17 20:43:52] Epoch:74, train_loss=0.63235, train_acc=0.86629, val_loss=1.05041, val_acc=0.85290, time=3.27112\n",
      "[2021/1/17 20:43:55] Epoch:75, train_loss=0.63178, train_acc=0.86661, val_loss=1.05041, val_acc=0.85217, time=2.97296\n",
      "[2021/1/17 20:43:58] Epoch:76, train_loss=0.63123, train_acc=0.86693, val_loss=1.05039, val_acc=0.85217, time=3.25486\n",
      "[2021/1/17 20:44:01] Epoch:77, train_loss=0.63070, train_acc=0.86757, val_loss=1.05037, val_acc=0.85290, time=3.16060\n",
      "[2021/1/17 20:44:04] Epoch:78, train_loss=0.63018, train_acc=0.86765, val_loss=1.05032, val_acc=0.85290, time=3.28431\n",
      "[2021/1/17 20:44:07] Epoch:79, train_loss=0.62972, train_acc=0.86838, val_loss=1.05035, val_acc=0.85507, time=2.95815\n",
      "[2021/1/17 20:44:11] Epoch:80, train_loss=0.62940, train_acc=0.86757, val_loss=1.05034, val_acc=0.84710, time=3.38781\n",
      "[2021/1/17 20:44:14] Epoch:81, train_loss=0.62957, train_acc=0.86894, val_loss=1.05068, val_acc=0.84710, time=3.33433\n",
      "[2021/1/17 20:44:14] Early stopping...\n",
      "[2021/1/17 20:44:14] Optimization Finished!\n",
      "[2021/1/17 20:44:15] Test set results: \n",
      "[2021/1/17 20:44:15] \t loss= 0.88863, accuracy= 0.85562, time= 0.82108\n",
      "[2021/1/17 20:44:15] Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 20:44:15]               precision    recall  f1-score   support\n",
      "[2021/1/17 20:44:15] \n",
      "[2021/1/17 20:44:15]            0     0.8309    0.9053    0.8665      2356\n",
      "[2021/1/17 20:44:15]            1     0.8530    0.8494    0.8512      1202\n",
      "[2021/1/17 20:44:15]            2     0.8866    0.8091    0.8461      2357\n",
      "[2021/1/17 20:44:15] \n",
      "[2021/1/17 20:44:15]     accuracy                         0.8556      5915\n",
      "[2021/1/17 20:44:15]    macro avg     0.8568    0.8546    0.8546      5915\n",
      "[2021/1/17 20:44:15] weighted avg     0.8576    0.8556    0.8553      5915\n",
      "[2021/1/17 20:44:15] \n",
      "[2021/1/17 20:44:15] Macro average Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 20:44:15] (0.8568203947582945, 0.8546150076503735, 0.8545947496080474, None)\n",
      "[2021/1/17 20:44:15] Micro average Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 20:44:15] (0.855621301775148, 0.855621301775148, 0.855621301775148, None)\n",
      "[2021/1/17 20:44:15] Embeddings:\n",
      "Word_embeddings:452] \n",
      "Train_doc_embeddings:13802\n",
      "Test_doc_embeddings:5915\n",
      "Word_embeddings::15] \n",
      "[[2.4791088  0.         0.         ... 1.4633484  0.9657705  0.        ]\n",
      " [0.5018314  0.36256915 0.5051993  ... 1.1402721  0.         0.20301618]\n",
      " [2.1077611  0.         0.         ... 1.4707468  0.4169647  0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.6628109  0.         0.29502577]\n",
      " [0.3249325  0.         0.         ... 1.828438   0.30296797 0.        ]\n",
      " [0.         0.21978515 0.4088971  ... 0.         0.         0.2673614 ]]\n"
     ]
    }
   ],
   "source": [
    "!venv/bin/python3 train.py pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/1/17 20:47:28] Epoch:1, train_loss=1.94754, train_acc=0.13943, val_loss=1.94101, val_acc=0.26455, time=0.21034\n",
      "[2021/1/17 20:47:28] Epoch:2, train_loss=1.87641, train_acc=0.31107, val_loss=1.93863, val_acc=0.26455, time=0.14678\n",
      "[2021/1/17 20:47:28] Epoch:3, train_loss=1.84132, train_acc=0.31810, val_loss=1.93438, val_acc=0.27513, time=0.13049\n",
      "[2021/1/17 20:47:29] Epoch:4, train_loss=1.80043, train_acc=0.33802, val_loss=1.92978, val_acc=0.33862, time=0.16264\n",
      "[2021/1/17 20:47:29] Epoch:5, train_loss=1.75999, train_acc=0.41886, val_loss=1.92578, val_acc=0.47090, time=0.15311\n",
      "[2021/1/17 20:47:29] Epoch:6, train_loss=1.72408, train_acc=0.57235, val_loss=1.92220, val_acc=0.59259, time=0.15597\n",
      "[2021/1/17 20:47:29] Epoch:7, train_loss=1.68956, train_acc=0.65202, val_loss=1.91879, val_acc=0.59259, time=0.15687\n",
      "[2021/1/17 20:47:29] Epoch:8, train_loss=1.65430, train_acc=0.68190, val_loss=1.91563, val_acc=0.60847, time=0.15486\n",
      "[2021/1/17 20:47:29] Epoch:9, train_loss=1.61945, train_acc=0.69889, val_loss=1.91282, val_acc=0.62434, time=0.13934\n",
      "[2021/1/17 20:47:30] Epoch:10, train_loss=1.58710, train_acc=0.70709, val_loss=1.91034, val_acc=0.62963, time=0.10919\n",
      "[2021/1/17 20:47:30] Epoch:11, train_loss=1.55792, train_acc=0.72759, val_loss=1.90792, val_acc=0.65079, time=0.12382\n",
      "[2021/1/17 20:47:30] Epoch:12, train_loss=1.53093, train_acc=0.75688, val_loss=1.90539, val_acc=0.69312, time=0.14409\n",
      "[2021/1/17 20:47:30] Epoch:13, train_loss=1.50507, train_acc=0.78676, val_loss=1.90281, val_acc=0.72487, time=0.14391\n",
      "[2021/1/17 20:47:30] Epoch:14, train_loss=1.48057, train_acc=0.80668, val_loss=1.90037, val_acc=0.73016, time=0.15270\n",
      "[2021/1/17 20:47:30] Epoch:15, train_loss=1.45813, train_acc=0.81839, val_loss=1.89821, val_acc=0.74074, time=0.16188\n",
      "[2021/1/17 20:47:30] Epoch:16, train_loss=1.43788, train_acc=0.82484, val_loss=1.89642, val_acc=0.75132, time=0.14528\n",
      "[2021/1/17 20:47:31] Epoch:17, train_loss=1.41956, train_acc=0.83011, val_loss=1.89502, val_acc=0.75132, time=0.14610\n",
      "[2021/1/17 20:47:31] Epoch:18, train_loss=1.40290, train_acc=0.82953, val_loss=1.89397, val_acc=0.74603, time=0.11730\n",
      "[2021/1/17 20:47:31] Epoch:19, train_loss=1.38785, train_acc=0.83070, val_loss=1.89314, val_acc=0.73545, time=0.15123\n",
      "[2021/1/17 20:47:31] Epoch:20, train_loss=1.37441, train_acc=0.83421, val_loss=1.89233, val_acc=0.74074, time=0.16181\n",
      "[2021/1/17 20:47:31] Epoch:21, train_loss=1.36210, train_acc=0.83890, val_loss=1.89140, val_acc=0.73545, time=0.15110\n",
      "[2021/1/17 20:47:31] Epoch:22, train_loss=1.35050, train_acc=0.84886, val_loss=1.89040, val_acc=0.75132, time=0.14494\n",
      "[2021/1/17 20:47:31] Epoch:23, train_loss=1.33979, train_acc=0.85354, val_loss=1.88949, val_acc=0.75661, time=0.14174\n",
      "[2021/1/17 20:47:32] Epoch:24, train_loss=1.33015, train_acc=0.85823, val_loss=1.88878, val_acc=0.76190, time=0.13494\n",
      "[2021/1/17 20:47:32] Epoch:25, train_loss=1.32121, train_acc=0.86233, val_loss=1.88828, val_acc=0.76190, time=0.10903\n",
      "[2021/1/17 20:47:32] Epoch:26, train_loss=1.31248, train_acc=0.86643, val_loss=1.88799, val_acc=0.76720, time=0.11353\n",
      "[2021/1/17 20:47:32] Epoch:27, train_loss=1.30394, train_acc=0.87522, val_loss=1.88784, val_acc=0.76720, time=0.10849\n",
      "[2021/1/17 20:47:32] Epoch:28, train_loss=1.29595, train_acc=0.88459, val_loss=1.88769, val_acc=0.76720, time=0.11045\n",
      "[2021/1/17 20:47:32] Epoch:29, train_loss=1.28849, train_acc=0.88869, val_loss=1.88742, val_acc=0.76720, time=0.11230\n",
      "[2021/1/17 20:47:32] Epoch:30, train_loss=1.28123, train_acc=0.89221, val_loss=1.88703, val_acc=0.76720, time=0.11495\n",
      "[2021/1/17 20:47:32] Epoch:31, train_loss=1.27416, train_acc=0.89748, val_loss=1.88664, val_acc=0.75661, time=0.14469\n",
      "[2021/1/17 20:47:32] Epoch:32, train_loss=1.26738, train_acc=0.90451, val_loss=1.88636, val_acc=0.75661, time=0.15153\n",
      "[2021/1/17 20:47:33] Epoch:33, train_loss=1.26089, train_acc=0.91037, val_loss=1.88623, val_acc=0.75661, time=0.14399\n",
      "[2021/1/17 20:47:33] Epoch:34, train_loss=1.25462, train_acc=0.91330, val_loss=1.88621, val_acc=0.75661, time=0.14399\n",
      "[2021/1/17 20:47:33] Epoch:35, train_loss=1.24865, train_acc=0.91681, val_loss=1.88623, val_acc=0.76190, time=0.14528\n",
      "[2021/1/17 20:47:33] Epoch:36, train_loss=1.24297, train_acc=0.92326, val_loss=1.88620, val_acc=0.76720, time=0.14508\n",
      "[2021/1/17 20:47:33] Epoch:37, train_loss=1.23742, train_acc=0.92794, val_loss=1.88611, val_acc=0.77249, time=0.14160\n",
      "[2021/1/17 20:47:33] Epoch:38, train_loss=1.23207, train_acc=0.93322, val_loss=1.88601, val_acc=0.77249, time=0.15281\n",
      "[2021/1/17 20:47:34] Epoch:39, train_loss=1.22707, train_acc=0.94025, val_loss=1.88596, val_acc=0.77249, time=0.15255\n",
      "[2021/1/17 20:47:34] Epoch:40, train_loss=1.22233, train_acc=0.94376, val_loss=1.88597, val_acc=0.77249, time=0.14847\n",
      "[2021/1/17 20:47:34] Epoch:41, train_loss=1.21774, train_acc=0.94786, val_loss=1.88603, val_acc=0.77249, time=0.15550\n",
      "[2021/1/17 20:47:34] Epoch:42, train_loss=1.21336, train_acc=0.94903, val_loss=1.88611, val_acc=0.77249, time=0.13424\n",
      "[2021/1/17 20:47:34] Epoch:43, train_loss=1.20925, train_acc=0.95255, val_loss=1.88616, val_acc=0.77249, time=0.10904\n",
      "[2021/1/17 20:47:34] Early stopping...\n",
      "[2021/1/17 20:47:34] Optimization Finished!\n",
      "[2021/1/17 20:47:34] Test set results: \n",
      "[2021/1/17 20:47:34] \t loss= 1.70590, accuracy= 0.76601, time= 0.04078\n",
      "[2021/1/17 20:47:34] Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 20:47:34]               precision    recall  f1-score   support\n",
      "[2021/1/17 20:47:34] \n",
      "[2021/1/17 20:47:34]            0     0.6667    0.4889    0.5641        45\n",
      "[2021/1/17 20:47:34]            1     0.7640    0.8197    0.7909       233\n",
      "[2021/1/17 20:47:34]            2     0.8593    0.8286    0.8436       140\n",
      "[2021/1/17 20:47:34]            3     0.6667    0.6724    0.6695       116\n",
      "[2021/1/17 20:47:34]            4     0.7540    0.7851    0.7692       121\n",
      "[2021/1/17 20:47:34]            5     0.7374    0.7935    0.7644        92\n",
      "[2021/1/17 20:47:34]            6     0.9038    0.7231    0.8034        65\n",
      "[2021/1/17 20:47:34] \n",
      "[2021/1/17 20:47:34]     accuracy                         0.7660       812\n",
      "[2021/1/17 20:47:34]    macro avg     0.7645    0.7302    0.7436       812\n",
      "[2021/1/17 20:47:34] weighted avg     0.7678    0.7660    0.7649       812\n",
      "[2021/1/17 20:47:34] \n",
      "[2021/1/17 20:47:34] Macro average Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 20:47:34] (0.7645401053972483, 0.7301851072461129, 0.74360065318493, None)\n",
      "[2021/1/17 20:47:34] Micro average Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 20:47:34] (0.7660098522167488, 0.7660098522167488, 0.7660098522167488, None)\n",
      "[2021/1/17 20:47:34] Embeddings:\n",
      "Word_embeddings:1343 \n",
      "Train_doc_embeddings:1896\n",
      "Test_doc_embeddings:812\n",
      "Word_embeddings::34] \n",
      "[[0.1454685  0.29786032 0.27916065 ... 0.16759144 0.05804364 0.20307359]\n",
      " [0.14272124 0.00766007 0.47747332 ... 0.         0.16162638 0.        ]\n",
      " [0.48401934 0.79374725 0.6522056  ... 0.         0.32820326 0.19983983]\n",
      " ...\n",
      " [0.44326642 0.         0.19971952 ... 0.04974031 0.21595012 0.2836688 ]\n",
      " [0.         0.5248942  0.03835521 ... 0.3925716  0.00101647 0.        ]\n",
      " [0.14112107 0.08749513 0.293279   ... 0.23508754 0.23564646 0.2606424 ]]\n"
     ]
    }
   ],
   "source": [
    "!venv/bin/python3 train.py cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/1/17 21:02:19] Epoch:1, train_loss=1.81051, train_acc=0.12787, val_loss=1.78906, val_acc=0.38095, time=0.39512\n",
      "[2021/1/17 21:02:19] Epoch:2, train_loss=1.76451, train_acc=0.35489, val_loss=1.78690, val_acc=0.35931, time=0.42189\n",
      "[2021/1/17 21:02:20] Epoch:3, train_loss=1.73866, train_acc=0.39895, val_loss=1.78506, val_acc=0.36797, time=0.40238\n",
      "[2021/1/17 21:02:20] Epoch:4, train_loss=1.71730, train_acc=0.44444, val_loss=1.78286, val_acc=0.43290, time=0.32582\n",
      "[2021/1/17 21:02:20] Epoch:5, train_loss=1.69430, train_acc=0.54119, val_loss=1.78040, val_acc=0.57143, time=0.41326\n",
      "[2021/1/17 21:02:21] Epoch:6, train_loss=1.66999, train_acc=0.65900, val_loss=1.77791, val_acc=0.66667, time=0.39221\n",
      "[2021/1/17 21:02:21] Epoch:7, train_loss=1.64573, train_acc=0.72318, val_loss=1.77548, val_acc=0.71429, time=0.39846\n",
      "[2021/1/17 21:02:22] Epoch:8, train_loss=1.62189, train_acc=0.73946, val_loss=1.77312, val_acc=0.71429, time=0.38295\n",
      "[2021/1/17 21:02:22] Epoch:9, train_loss=1.59847, train_acc=0.75383, val_loss=1.77087, val_acc=0.74026, time=0.40998\n",
      "[2021/1/17 21:02:22] Epoch:10, train_loss=1.57582, train_acc=0.75527, val_loss=1.76885, val_acc=0.74026, time=0.39754\n",
      "[2021/1/17 21:02:23] Epoch:11, train_loss=1.55478, train_acc=0.76006, val_loss=1.76710, val_acc=0.72294, time=0.38143\n",
      "[2021/1/17 21:02:23] Epoch:12, train_loss=1.53600, train_acc=0.76628, val_loss=1.76559, val_acc=0.72294, time=0.31645\n",
      "[2021/1/17 21:02:23] Epoch:13, train_loss=1.51945, train_acc=0.77107, val_loss=1.76423, val_acc=0.73593, time=0.35115\n",
      "[2021/1/17 21:02:24] Epoch:14, train_loss=1.50442, train_acc=0.77538, val_loss=1.76296, val_acc=0.74459, time=0.36100\n",
      "[2021/1/17 21:02:24] Epoch:15, train_loss=1.49040, train_acc=0.78161, val_loss=1.76184, val_acc=0.74026, time=0.36229\n",
      "[2021/1/17 21:02:25] Epoch:16, train_loss=1.47764, train_acc=0.78592, val_loss=1.76095, val_acc=0.74892, time=0.42203\n",
      "[2021/1/17 21:02:25] Epoch:17, train_loss=1.46640, train_acc=0.78544, val_loss=1.76029, val_acc=0.74026, time=0.40799\n",
      "[2021/1/17 21:02:25] Epoch:18, train_loss=1.45646, train_acc=0.78879, val_loss=1.75980, val_acc=0.74892, time=0.41237\n",
      "[2021/1/17 21:02:26] Epoch:19, train_loss=1.44759, train_acc=0.79358, val_loss=1.75942, val_acc=0.74892, time=0.44253\n",
      "[2021/1/17 21:02:26] Epoch:20, train_loss=1.43961, train_acc=0.79885, val_loss=1.75907, val_acc=0.74892, time=0.34913\n",
      "[2021/1/17 21:02:26] Epoch:21, train_loss=1.43210, train_acc=0.80220, val_loss=1.75874, val_acc=0.76623, time=0.32236\n",
      "[2021/1/17 21:02:27] Epoch:22, train_loss=1.42482, train_acc=0.81034, val_loss=1.75850, val_acc=0.76190, time=0.31094\n",
      "[2021/1/17 21:02:27] Epoch:23, train_loss=1.41804, train_acc=0.81897, val_loss=1.75840, val_acc=0.76190, time=0.41727\n",
      "[2021/1/17 21:02:28] Epoch:24, train_loss=1.41195, train_acc=0.82280, val_loss=1.75837, val_acc=0.76623, time=0.35631\n",
      "[2021/1/17 21:02:28] Epoch:25, train_loss=1.40618, train_acc=0.83190, val_loss=1.75832, val_acc=0.76623, time=0.35526\n",
      "[2021/1/17 21:02:28] Epoch:26, train_loss=1.40027, train_acc=0.83860, val_loss=1.75826, val_acc=0.76190, time=0.35991\n",
      "[2021/1/17 21:02:29] Epoch:27, train_loss=1.39445, train_acc=0.84387, val_loss=1.75825, val_acc=0.76190, time=0.38345\n",
      "[2021/1/17 21:02:29] Epoch:28, train_loss=1.38910, train_acc=0.85010, val_loss=1.75830, val_acc=0.74892, time=0.37749\n",
      "[2021/1/17 21:02:29] Epoch:29, train_loss=1.38404, train_acc=0.85393, val_loss=1.75836, val_acc=0.74892, time=0.38594\n",
      "[2021/1/17 21:02:30] Epoch:30, train_loss=1.37897, train_acc=0.86111, val_loss=1.75841, val_acc=0.75758, time=0.33214\n",
      "[2021/1/17 21:02:30] Epoch:31, train_loss=1.37392, train_acc=0.86638, val_loss=1.75848, val_acc=0.74892, time=0.33562\n",
      "[2021/1/17 21:02:30] Early stopping...\n",
      "[2021/1/17 21:02:30] Optimization Finished!\n",
      "[2021/1/17 21:02:30] Test set results: \n",
      "[2021/1/17 21:02:30] \t loss= 1.65276, accuracy= 0.72608, time= 0.12885\n",
      "[2021/1/17 21:02:30] Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 21:02:30]               precision    recall  f1-score   support\n",
      "[2021/1/17 21:02:30] \n",
      "[2021/1/17 21:02:30]            0     0.7971    0.7933    0.7952       208\n",
      "[2021/1/17 21:02:30]            1     0.7568    0.7467    0.7517       150\n",
      "[2021/1/17 21:02:30]            2     0.6872    0.7672    0.7250       189\n",
      "[2021/1/17 21:02:30]            3     0.7377    0.7803    0.7584       173\n",
      "[2021/1/17 21:02:30]            4     0.6897    0.6863    0.6880       204\n",
      "[2021/1/17 21:02:30]            5     0.5854    0.3478    0.4364        69\n",
      "[2021/1/17 21:02:30] \n",
      "[2021/1/17 21:02:30]     accuracy                         0.7261       993\n",
      "[2021/1/17 21:02:30]    macro avg     0.7090    0.6869    0.6924       993\n",
      "[2021/1/17 21:02:30] weighted avg     0.7230    0.7261    0.7219       993\n",
      "[2021/1/17 21:02:30] \n",
      "[2021/1/17 21:02:30] Macro average Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 21:02:30] (0.708964656934405, 0.6869298470335594, 0.6924349776428365, None)\n",
      "[2021/1/17 21:02:30] Micro average Test Precision, Recall and F1-Score...\n",
      "[2021/1/17 21:02:30] (0.7260825780463243, 0.7260825780463243, 0.7260825780463243, None)\n",
      "[2021/1/17 21:02:30] Embeddings:\n",
      "Word_embeddings:3515 \n",
      "Train_doc_embeddings:2319\n",
      "Test_doc_embeddings:993\n",
      "Word_embeddings::30] \n",
      "[[0.16471298 0.16343315 0.19853133 ... 0.39090103 0.26974383 0.546054  ]\n",
      " [0.         0.3382577  0.1001628  ... 0.00496465 0.13998905 0.37520996]\n",
      " [0.15608153 0.03974877 0.         ... 0.25162306 0.20541814 0.        ]\n",
      " ...\n",
      " [0.3253109  0.1486606  0.18521316 ... 0.2619062  0.07197864 0.25857145]\n",
      " [0.09422912 0.         0.16670382 ... 0.3093291  0.19663246 0.05479228]\n",
      " [0.19621433 0.1216694  0.09011918 ... 0.28176847 0.05079595 0.02445806]]\n"
     ]
    }
   ],
   "source": [
    "!venv/bin/python3 train.py citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
